{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitbarlew/AnyGPT-on-Colab---OLLAMA-with-UI-on-Colab/blob/main/AnyGPT_Colab_OLLAMA_with_UI_on_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQCVA1qum078"
      },
      "source": [
        "# AnyGPT with UI using OLLAMA on Google Colab\n",
        "\n",
        "The following instructions will guide you through the process of downloading, installing, and initiating an Ollama instance along with a ChatGPT inspired user interface Nextjs-ollama-ui, created by Jakobhoeg@github.\n",
        "\n",
        "This guide provides steps to make this user interface accessible over the public internet using Localtunnel running on Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Download and install Ollama.\n",
        "Below code downloads, installs and runs Ollama instance in the background."
      ],
      "metadata": {
        "id": "oMYaPncd0oti"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJRLFlY9yWnO"
      },
      "outputs": [],
      "source": [
        "# Pull Ollama install script and execute\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "# Run Ollama service in the background\n",
        "!sudo ollama serve &>/dev/null&"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_zGoFeqpkVu"
      },
      "source": [
        "# Step 2 Update Node.js to the latest version.\n",
        "This section guides you through upgrading Node.js on our machine to the latest version. At the time of writing this notebook, colab by default uses version v14.16., while our UI application requires Node.js version 18 or higher.\n",
        "\n",
        "To achieve this, we'll use the official Node.js script to fetch and install the latest available version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwCEbSQSfxaH"
      },
      "outputs": [],
      "source": [
        "# Download the install script for the current Node.js version and execute it.\n",
        "!curl -fsSL https://deb.nodesource.com/setup_current.x | sh\n",
        "# Update the system's package index.\n",
        "!sudo apt-get update\n",
        "# Install Node.js.\n",
        "!sudo apt-get install -y nodejs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDeMx5lmpuKM"
      },
      "source": [
        "# Step 3 Download and run UI application.\n",
        "Now, we will download a repository with Nextjs-ollama-LLM-ui, user interface similar to ChatGPT. We will utilize the NPM package manager to install its dependencies and execute it in the background. By default, the interface is configured to operate on local port 3000 - we will use this information later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Hh9FEb-ynfT"
      },
      "outputs": [],
      "source": [
        "# Clone the repository from GitHub.\n",
        "!git clone https://github.com/jakobhoeg/nextjs-ollama-llm-ui\n",
        "# Change directory to the downloaded project directory\n",
        "%cd nextjs-ollama-llm-ui\n",
        "# Rename example.env file to .env to be used as our default configuration\n",
        "!mv .example.env .env\n",
        "# Install dependencies using Node Package Manager\n",
        "!npm install\n",
        "# Start the web server, discard all outputs and run in the background.\n",
        "!npm run dev &>/dev/null&"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4 Check Colab's instance Public IP address.\n",
        "The following step involves checking the public IP address of the Google Colab instance. This IP address will later be used as a password for the security check used by localtunnel service."
      ],
      "metadata": {
        "id": "2SskR_wD0u0D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XanXk53Fyb1q"
      },
      "outputs": [],
      "source": [
        "# Retrieve Public IP address of Google Colab's instance. This will be used as a password for our Tunnel.\n",
        "!curl ifconfig.me"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5 Install Localtunnel and expose UI to the internet.\n",
        "Finally let's install and run localtunnel. This tool will expose our user interface's default API, which runs on port 3000, to the internet. This step will result in URL that can be used for external access to our UI. During the first attempt to open the URL, as a password provide IP address we retrieved in step 4."
      ],
      "metadata": {
        "id": "eqZd81nQ0yUP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tD4C0vay4rD"
      },
      "outputs": [],
      "source": [
        "# Install localtunnel globally using NPM.\n",
        "!npm install localtunnel\n",
        "# Start localtunnel and expose port 3000 to the internet.\n",
        "!npx localtunnel --port 3000"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}